#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆ 2D Instance æ•ˆç‡åˆ†æè„šæœ¬
å¢åŠ äº†æ ‡æ³¨ç›®æ ‡å’Œæ ‡æ³¨é€Ÿåº¦çš„æ€»ä½“å’Œä¸ªäººåˆ†æ
"""

import sys
import json
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
import argparse
import numpy as np

try:
    from influxdb_client.client.influxdb_client import InfluxDBClient
    from influxdb_client.client.query_api import QueryApi
except ImportError:
    print("âŒ ç¼ºå°‘ influxdb-client ä¾èµ–")
    print("è¯·å®‰è£…: pip install influxdb-client pandas numpy")
    sys.exit(1)

# InfluxDB é…ç½®
INFLUXDB_CONFIG = {
    'url': 'http://localhost:8087',
    'token': 'Y7anaf-f1yBZaDe3M1pCy5LdfVTxH8g8odTzf0UOJd_0V4BROJmQ7HlFDTLefh8GIoWNNkOgKHdnKAeR7KMhqw==',
    'org': 'xtreme1',
    'bucket': 'efficiency_events'
}

# 2D Instanceç±»å‹æ˜ å°„
INSTANCE_TYPE_MAPPING = {
    'rect': 'cuboid',
    'rectangle': 'cuboid', 
    'bounding_box': 'cuboid',
    'BOUNDING_BOX': 'cuboid',
    'RECTANGLE': 'cuboid',
    'polygon': 'polygon',
    'POLYGON': 'polygon',
    'polyline': 'polyline',
    'POLYLINE': 'polyline',
    'iss': 'issinstance',
    'iss-rect': 'issinstance',
    'iss_unified': 'issinstance',
    'ISS': 'issinstance',
    'ISS_UNIFIED': 'issinstance',
    'ISS_RECT': 'issinstance',
    'keypoint': 'keypoint',
    'key-point': 'keypoint',
    'KEY_POINT': 'keypoint',
}

class Enhanced2DAnalyzer:
    def __init__(self):
        """åˆå§‹åŒ–å¢å¼ºç‰ˆ 2D Instance åˆ†æå™¨"""
        self.client = None
        self.query_api = None
        
    def connect(self) -> bool:
        """è¿æ¥åˆ° InfluxDB"""
        try:
            self.client = InfluxDBClient(
                url=INFLUXDB_CONFIG['url'],
                token=INFLUXDB_CONFIG['token'],
                org=INFLUXDB_CONFIG['org']
            )
            self.query_api = self.client.query_api()
            
            health = self.client.health()
            if health.status == "pass":
                print("âœ… InfluxDB è¿æ¥æˆåŠŸ")
                return True
            else:
                print(f"âŒ InfluxDB å¥åº·æ£€æŸ¥å¤±è´¥: {health.status}")
                return False
                
        except Exception as e:
            print(f"âŒ InfluxDB è¿æ¥å¤±è´¥: {e}")
            return False
    
    def query_2d_instance_data(self, hours: int = 1) -> Optional[List[Dict]]:
        """æŸ¥è¯¢2D Instanceç›¸å…³çš„EFFMäº‹ä»¶æ•°æ®"""
        try:
            query = f'''
            from(bucket: "{INFLUXDB_CONFIG['bucket']}")
              |> range(start: -{hours}h)
              |> filter(fn: (r) => r["_measurement"] == "efficiency_events")
              |> filter(fn: (r) => 
                r["annotationType"] == "rect" or
                r["annotationType"] == "rectangle" or 
                r["annotationType"] == "bounding_box" or
                r["annotationType"] == "cuboid" or
                r["annotationType"] == "polygon" or
                r["annotationType"] == "polyline" or
                r["meta_toolType"] == "rect" or
                r["meta_toolType"] == "rectangle" or
                r["meta_toolType"] == "polygon" or
                r["meta_toolType"] == "polyline" or
                r["meta_toolType"] == "iss" or
                r["toolType"] == "rect" or
                r["toolType"] == "rectangle" or
                r["toolType"] == "polygon" or
                r["toolType"] == "polyline" or
                r["toolType"] == "iss" or
                r["field"] == "rect" or 
                r["field"] == "polygon" or 
                r["field"] == "polyline" or 
                r["field"] == "iss"
              )
              |> sort(columns: ["_time"], desc: false)
            '''
            
            print(f"ğŸ” æ­£åœ¨æŸ¥è¯¢æœ€è¿‘ {hours} å°æ—¶çš„2D Instanceæ•°æ®...")
            
            result = self.query_api.query(org=INFLUXDB_CONFIG['org'], query=query)
            
            records = []
            for table in result:
                for record in table.records:
                    records.append({
                        'time': record.get_time(),
                        'measurement': record.get_measurement(),
                        'field': record.get_field(),
                        'value': record.get_value(),
                        **record.values
                    })
            
            print(f"âœ… è·å–åˆ° {len(records)} æ¡2D Instanceè®°å½•")
            return records
            
        except Exception as e:
            print(f"âŒ æŸ¥è¯¢2D Instanceæ•°æ®å¤±è´¥: {e}")
            return None
    
    def normalize_instance_type(self, tool_type: str) -> str:
        """æ ‡å‡†åŒ–å®ä¾‹ç±»å‹åç§°"""
        if not tool_type:
            return 'unknown'
        
        tool_type_clean = str(tool_type).strip().lower()
        return INSTANCE_TYPE_MAPPING.get(tool_type_clean, tool_type_clean)
    
    def analyze_annotation_targets_overall(self, df: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†ææ€»ä½“æ ‡æ³¨ç›®æ ‡"""
        if df.empty:
            return {"error": "æ²¡æœ‰æ•°æ®å¯åˆ†æ"}
        
        # æ ‡å‡†åŒ–å®ä¾‹ç±»å‹
        df['normalized_instance_type'] = df.apply(
            lambda row: self.normalize_instance_type(
                row.get('annotationType') or 
                row.get('meta_toolType') or 
                row.get('toolType') or 
                row.get('tool_type') or 
                row.get('field', '')
            ), axis=1
        )
        
        # è¿‡æ»¤2D instanceæ•°æ®
        instance_types = ['cuboid', 'polygon', 'polyline', 'issinstance']
        instance_df = df[df['normalized_instance_type'].isin(instance_types)]
        
        if instance_df.empty:
            return {"error": "æ²¡æœ‰æ‰¾åˆ°2D Instanceç›¸å…³æ•°æ®"}
        
        # è¿‡æ»¤å®Œæˆçš„æ ‡æ³¨äº‹ä»¶
        completion_df = self._filter_completion_events(instance_df)
        
        # åˆ†ææ ‡æ³¨ç›®æ ‡ç±»å‹åˆ†å¸ƒ
        target_analysis = {
            "total_annotations": len(completion_df),
            "target_type_distribution": completion_df['normalized_instance_type'].value_counts().to_dict(),
            "target_type_percentages": (completion_df['normalized_instance_type'].value_counts() / len(completion_df) * 100).to_dict(),
            "most_common_target": completion_df['normalized_instance_type'].mode().iloc[0] if not completion_df.empty else None,
            "target_diversity": len(completion_df['normalized_instance_type'].unique()),
        }
        
        # åˆ†ææ ‡æ³¨å¯¹è±¡çš„å¤æ‚åº¦ï¼ˆå¦‚æœæœ‰ç›¸å…³å…ƒæ•°æ®ï¼‰
        complexity_analysis = self._analyze_target_complexity(completion_df)
        target_analysis["target_complexity"] = complexity_analysis
        
        return target_analysis
    
    def analyze_annotation_speed_overall(self, df: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†ææ€»ä½“æ ‡æ³¨é€Ÿåº¦"""
        if df.empty:
            return {"error": "æ²¡æœ‰æ•°æ®å¯åˆ†æ"}
        
        # æ ‡å‡†åŒ–å®ä¾‹ç±»å‹
        df['normalized_instance_type'] = df.apply(
            lambda row: self.normalize_instance_type(
                row.get('annotationType') or 
                row.get('meta_toolType') or 
                row.get('toolType') or 
                row.get('tool_type') or 
                row.get('field', '')
            ), axis=1
        )
        
        # è¿‡æ»¤2D instanceæ•°æ®
        instance_types = ['cuboid', 'polygon', 'polyline', 'issinstance']
        instance_df = df[df['normalized_instance_type'].isin(instance_types)]
        
        if instance_df.empty:
            return {"error": "æ²¡æœ‰æ‰¾åˆ°2D Instanceç›¸å…³æ•°æ®"}
        
        # è½¬æ¢æ—¶é—´å­—æ®µ
        instance_df['time'] = pd.to_datetime(instance_df['time'])
        
        # è¿‡æ»¤å®Œæˆçš„æ ‡æ³¨äº‹ä»¶
        completion_df = self._filter_completion_events(instance_df)
        
        if completion_df.empty:
            return {"error": "æ²¡æœ‰å®Œæˆçš„æ ‡æ³¨äº‹ä»¶"}
        
        # è®¡ç®—æ—¶é—´èŒƒå›´
        time_range = completion_df['time'].max() - completion_df['time'].min()
        total_hours = time_range.total_seconds() / 3600 if time_range.total_seconds() > 0 else 1
        
        # æ ‡æ³¨é€Ÿåº¦åˆ†æ
        speed_analysis = {
            "time_range": {
                "start": completion_df['time'].min().isoformat(),
                "end": completion_df['time'].max().isoformat(),
                "duration_hours": total_hours
            },
            "overall_speed": {
                "annotations_per_hour": len(completion_df) / total_hours,
                "annotations_per_minute": len(completion_df) / (total_hours * 60),
                "average_time_between_annotations": time_range.total_seconds() / len(completion_df) if len(completion_df) > 1 else 0
            }
        }
        
        # æŒ‰ç±»å‹çš„æ ‡æ³¨é€Ÿåº¦
        speed_by_type = {}
        for inst_type in completion_df['normalized_instance_type'].unique():
            type_data = completion_df[completion_df['normalized_instance_type'] == inst_type]
            speed_by_type[str(inst_type)] = {
                "count": len(type_data),
                "annotations_per_hour": len(type_data) / total_hours,
                "percentage_of_total": len(type_data) / len(completion_df) * 100
            }
        
        speed_analysis["speed_by_type"] = speed_by_type
        
        # åˆ†ææ¯ä¸ªç‰©ä½“çš„å¹³å‡å®Œæˆæ—¶é—´ï¼ˆæŒ‰ç±»å‹ï¼‰
        completion_time_analysis = self._analyze_completion_time_by_type(completion_df)
        speed_analysis["completion_time_by_type"] = completion_time_analysis
        
        # æ—¶é—´æ®µåˆ†æï¼ˆæŒ‰å°æ—¶ï¼‰
        hourly_analysis = self._analyze_hourly_speed(completion_df)
        speed_analysis["hourly_patterns"] = hourly_analysis
        
        return speed_analysis
    
    def analyze_annotation_targets_individual(self, df: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†æä¸ªäººæ ‡æ³¨ç›®æ ‡"""
        if df.empty:
            return {"error": "æ²¡æœ‰æ•°æ®å¯åˆ†æ"}
        
        # æ ‡å‡†åŒ–å®ä¾‹ç±»å‹
        df['normalized_instance_type'] = df.apply(
            lambda row: self.normalize_instance_type(
                row.get('annotationType') or 
                row.get('meta_toolType') or 
                row.get('toolType') or 
                row.get('tool_type') or 
                row.get('field', '')
            ), axis=1
        )
        
        # è¿‡æ»¤2D instanceæ•°æ®
        instance_types = ['cuboid', 'polygon', 'polyline', 'issinstance']
        instance_df = df[df['normalized_instance_type'].isin(instance_types)]
        
        if instance_df.empty:
            return {"error": "æ²¡æœ‰æ‰¾åˆ°2D Instanceç›¸å…³æ•°æ®"}
        
        # å¯»æ‰¾ç”¨æˆ·å­—æ®µ
        user_col = self._find_user_column(instance_df)
        if not user_col:
            return {"error": "æœªæ‰¾åˆ°ç”¨æˆ·ä¿¡æ¯"}
        
        # è¿‡æ»¤å®Œæˆçš„æ ‡æ³¨äº‹ä»¶
        completion_df = self._filter_completion_events(instance_df)
        
        individual_targets = {}
        
        for user_id in completion_df[user_col].dropna().unique():
            user_data = completion_df[completion_df[user_col] == user_id]
            
            if len(user_data) > 0:
                # ç”¨æˆ·çš„ç›®æ ‡ç±»å‹åˆ†æ
                user_targets = user_data['normalized_instance_type'].value_counts()
                
                individual_targets[str(user_id)] = {
                    "total_annotations": len(user_data),
                    "target_distribution": user_targets.to_dict(),
                    "target_percentages": (user_targets / len(user_data) * 100).to_dict(),
                    "most_common_target": user_targets.index[0] if len(user_targets) > 0 else None,
                    "target_diversity": len(user_targets),
                    "specialization_score": self._calculate_specialization_score(user_targets),
                    "complexity_preference": self._analyze_user_complexity_preference(user_data)
                }
        
        # ç”¨æˆ·æ¯”è¾ƒåˆ†æ
        comparison_analysis = self._compare_user_targets(individual_targets)
        
        return {
            "individual_analysis": individual_targets,
            "comparison_analysis": comparison_analysis
        }
    
    def analyze_annotation_speed_individual(self, df: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†æä¸ªäººæ ‡æ³¨é€Ÿåº¦"""
        if df.empty:
            return {"error": "æ²¡æœ‰æ•°æ®å¯åˆ†æ"}
        
        # æ ‡å‡†åŒ–å®ä¾‹ç±»å‹
        df['normalized_instance_type'] = df.apply(
            lambda row: self.normalize_instance_type(
                row.get('annotationType') or 
                row.get('meta_toolType') or 
                row.get('toolType') or 
                row.get('tool_type') or 
                row.get('field', '')
            ), axis=1
        )
        
        # è¿‡æ»¤2D instanceæ•°æ®
        instance_types = ['cuboid', 'polygon', 'polyline', 'issinstance']
        instance_df = df[df['normalized_instance_type'].isin(instance_types)]
        
        if instance_df.empty:
            return {"error": "æ²¡æœ‰æ‰¾åˆ°2D Instanceç›¸å…³æ•°æ®"}
        
        # è½¬æ¢æ—¶é—´å­—æ®µ
        instance_df['time'] = pd.to_datetime(instance_df['time'])
        
        # å¯»æ‰¾ç”¨æˆ·å­—æ®µ
        user_col = self._find_user_column(instance_df)
        if not user_col:
            return {"error": "æœªæ‰¾åˆ°ç”¨æˆ·ä¿¡æ¯"}
        
        # è¿‡æ»¤å®Œæˆçš„æ ‡æ³¨äº‹ä»¶
        completion_df = self._filter_completion_events(instance_df)
        
        individual_speeds = {}
        
        for user_id in completion_df[user_col].dropna().unique():
            user_data = completion_df[completion_df[user_col] == user_id].sort_values('time')
            
            if len(user_data) > 0:
                # è®¡ç®—ç”¨æˆ·çš„æ—¶é—´èŒƒå›´
                user_time_range = user_data['time'].max() - user_data['time'].min()
                user_hours = user_time_range.total_seconds() / 3600 if user_time_range.total_seconds() > 0 else 1
                
                # ç”¨æˆ·é€Ÿåº¦åˆ†æ
                user_speed = {
                    "session_info": {
                        "start_time": user_data['time'].min().isoformat(),
                        "end_time": user_data['time'].max().isoformat(),
                        "duration_hours": user_hours,
                        "total_annotations": len(user_data)
                    },
                    "speed_metrics": {
                        "annotations_per_hour": len(user_data) / user_hours,
                        "annotations_per_minute": len(user_data) / (user_hours * 60),
                        "average_interval_seconds": user_time_range.total_seconds() / len(user_data) if len(user_data) > 1 else 0
                    }
                }
                
                # æŒ‰ç±»å‹çš„é€Ÿåº¦
                speed_by_type = {}
                for inst_type in user_data['normalized_instance_type'].unique():
                    type_data = user_data[user_data['normalized_instance_type'] == inst_type]
                    speed_by_type[str(inst_type)] = {
                        "count": len(type_data),
                        "annotations_per_hour": len(type_data) / user_hours,
                        "percentage_of_user_total": len(type_data) / len(user_data) * 100
                    }
                
                user_speed["speed_by_type"] = speed_by_type
                
                # é€Ÿåº¦è¶‹åŠ¿åˆ†æ
                user_speed["speed_trend"] = self._analyze_user_speed_trend(user_data)
                
                # æ•ˆç‡ç­‰çº§
                user_speed["efficiency_level"] = self._calculate_efficiency_level(user_speed["speed_metrics"]["annotations_per_hour"])
                
                # ç”¨æˆ·çš„å®Œæˆæ—¶é—´åˆ†æ
                user_completion_time = self._analyze_completion_time_by_type(user_data)
                user_speed["completion_time_by_type"] = user_completion_time
                
                individual_speeds[str(user_id)] = user_speed
        
        # ç”¨æˆ·é€Ÿåº¦æ¯”è¾ƒ
        speed_comparison = self._compare_user_speeds(individual_speeds)
        
        return {
            "individual_analysis": individual_speeds,
            "speed_comparison": speed_comparison
        }
    
    def _filter_completion_events(self, df: pd.DataFrame) -> pd.DataFrame:
        """è¿‡æ»¤å®Œæˆçš„æ ‡æ³¨äº‹ä»¶"""
        completion_mask = (
            (df.get('action', pd.Series([], dtype='object')).fillna('') == 'complete') |
            (df.get('event_type', pd.Series([], dtype='object')).fillna('').str.contains('completion|completed', case=False, na=False)) |
            (df.get('field', pd.Series([], dtype='object')).fillna('').str.contains('completion|completed', case=False, na=False))
        )
        
        completion_df = df[completion_mask]
        
        if completion_df.empty:
            completion_df = df  # å¦‚æœæ²¡æœ‰æ˜ç¡®çš„å®Œæˆæ ‡è¯†ï¼Œä½¿ç”¨å…¨éƒ¨æ•°æ®
        
        return completion_df
    
    def _find_user_column(self, df: pd.DataFrame) -> Optional[str]:
        """å¯»æ‰¾ç”¨æˆ·å­—æ®µ"""
        user_fields = ['user_id', 'userId', 'createdBy', 'created_by']
        for field in user_fields:
            if field in df.columns:
                return field
        return None
    
    def _analyze_target_complexity(self, df: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†ææ ‡æ³¨ç›®æ ‡å¤æ‚åº¦"""
        complexity_analysis = {
            "simple_shapes": 0,
            "complex_shapes": 0,
            "average_complexity": 0
        }
        
        # åŸºäºç±»å‹åˆ¤æ–­å¤æ‚åº¦
        type_complexity = {
            'cuboid': 1,  # ç®€å•
            'polygon': 3,  # å¤æ‚
            'polyline': 2,  # ä¸­ç­‰
            'issinstance': 4,  # æœ€å¤æ‚
            'keypoint': 1  # ç®€å•
        }
        
        for inst_type in df['normalized_instance_type'].unique():
            count = len(df[df['normalized_instance_type'] == inst_type])
            complexity = type_complexity.get(str(inst_type), 2)
            
            if complexity <= 2:
                complexity_analysis["simple_shapes"] += count
            else:
                complexity_analysis["complex_shapes"] += count
        
        total_annotations = len(df)
        if total_annotations > 0:
            weighted_complexity = sum(
                len(df[df['normalized_instance_type'] == inst_type]) * type_complexity.get(str(inst_type), 2)
                for inst_type in df['normalized_instance_type'].unique()
            )
            complexity_analysis["average_complexity"] = weighted_complexity / total_annotations
        
        return complexity_analysis
    
    def _analyze_completion_time_by_type(self, df: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†ææ¯ä¸ªç‰©ä½“çš„å¹³å‡å®Œæˆæ—¶é—´ï¼ˆæŒ‰ç±»å‹ï¼‰"""
        completion_time_analysis = {}
        
        # å¯»æ‰¾æ—¶é•¿ç›¸å…³å­—æ®µ
        duration_fields = ['meta_averagePointInterval', 'meta_duration', 'duration', 'completion_time', 'time_taken', 'value']
        duration_col = None
        
        for field in duration_fields:
            if field in df.columns:
                # å°è¯•è½¬æ¢ä¸ºæ•°å€¼ï¼ˆå¤„ç†å­—ç¬¦ä¸²æ•°å€¼ï¼‰
                try:
                    numeric_values = pd.to_numeric(df[field], errors='coerce').dropna()
                    if len(numeric_values) > 0:
                        if field == 'meta_averagePointInterval':
                            # meta_averagePointInterval é€šå¸¸åœ¨ 100-50000 æ¯«ç§’èŒƒå›´
                            if numeric_values.min() > 0 and numeric_values.max() < 100000:
                                duration_col = field
                                break
                        elif field != 'duration':  # æ’é™¤å¼‚å¸¸å¤§çš„ duration å­—æ®µ
                            # å…¶ä»–å­—æ®µåº”è¯¥åœ¨åˆç†èŒƒå›´å†…
                            if numeric_values.min() > 0 and numeric_values.max() < 3600000:  # å°äº1å°æ—¶
                                duration_col = field
                                break
                except Exception:
                    continue
        
        if not duration_col:
            return {
                "error": "æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ—¶é•¿æ•°æ®",
                "available_fields": list(df.columns)
            }
        
        # è½¬æ¢ä¸ºæ•°å€¼å‹
        df[f'{duration_col}_numeric'] = pd.to_numeric(df[duration_col], errors='coerce')
        
        # è¿‡æ»¤æœ‰æ•ˆçš„æ—¶é•¿æ•°æ®
        valid_df = df[(df[f'{duration_col}_numeric'].notna()) & (df[f'{duration_col}_numeric'] > 0)]
        
        if valid_df.empty:
            return {"error": "æ²¡æœ‰æœ‰æ•ˆçš„æ—¶é•¿æ•°æ®"}
        
        # æŒ‰ç±»å‹åˆ†æå®Œæˆæ—¶é—´
        for inst_type in valid_df['normalized_instance_type'].unique():
            type_data = valid_df[valid_df['normalized_instance_type'] == inst_type]
            durations = type_data[f'{duration_col}_numeric']
            
            if len(durations) > 0:
                # è½¬æ¢æ¯«ç§’ä¸ºç§’ï¼ˆå¦‚æœæ˜¯æ¯«ç§’çº§åˆ«çš„æ•°æ®ï¼‰
                if duration_col == 'meta_averagePointInterval' and durations.mean() > 1000:
                    durations_seconds = durations / 1000  # æ¯«ç§’è½¬ç§’
                    unit = "ç§’"
                else:
                    durations_seconds = durations
                    unit = "ç§’"
                
                completion_time_analysis[str(inst_type)] = {
                    "count": len(durations),
                    "average_completion_time": float(durations_seconds.mean()),
                    "median_completion_time": float(durations_seconds.median()),
                    "min_completion_time": float(durations_seconds.min()),
                    "max_completion_time": float(durations_seconds.max()),
                    "std_completion_time": float(durations_seconds.std()) if len(durations) > 1 else 0,
                    "unit": unit,
                    "data_source": duration_col,
                    "percentiles": {
                        "25th": float(durations_seconds.quantile(0.25)),
                        "75th": float(durations_seconds.quantile(0.75)),
                        "90th": float(durations_seconds.quantile(0.90))
                    }
                }
        
        # æ·»åŠ æ€»ä½“ç»Ÿè®¡
        if completion_time_analysis:
            all_durations = valid_df[f'{duration_col}_numeric']
            if duration_col == 'meta_averagePointInterval' and all_durations.mean() > 1000:
                all_durations_seconds = all_durations / 1000
                unit = "ç§’"
            else:
                all_durations_seconds = all_durations
                unit = "ç§’"
            
            completion_time_analysis["overall"] = {
                "count": len(all_durations),
                "average_completion_time": float(all_durations_seconds.mean()),
                "median_completion_time": float(all_durations_seconds.median()),
                "min_completion_time": float(all_durations_seconds.min()),
                "max_completion_time": float(all_durations_seconds.max()),
                "std_completion_time": float(all_durations_seconds.std()) if len(all_durations) > 1 else 0,
                "unit": unit,
                "data_source": duration_col
            }
        
        return completion_time_analysis
    
    def _analyze_hourly_speed(self, df: pd.DataFrame) -> Dict[str, Any]:
        """åˆ†ææ¯å°æ—¶çš„æ ‡æ³¨é€Ÿåº¦æ¨¡å¼"""
        df['hour'] = df['time'].dt.hour
        hourly_counts = df['hour'].value_counts().sort_index()
        
        return {
            "peak_hour": int(hourly_counts.idxmax()) if not hourly_counts.empty else None,
            "peak_hour_count": int(hourly_counts.max()) if not hourly_counts.empty else 0,
            "hourly_distribution": hourly_counts.to_dict(),
            "most_productive_hours": hourly_counts.nlargest(3).to_dict()
        }
    
    def _calculate_specialization_score(self, target_counts: pd.Series) -> float:
        """è®¡ç®—ç”¨æˆ·ä¸“ä¸šåŒ–åˆ†æ•°ï¼ˆ0-100ï¼Œè¶Šé«˜è¶Šä¸“ä¸šåŒ–ï¼‰"""
        if len(target_counts) <= 1:
            return 100.0
        
        # åŸºäºé¦™å†œç†µè®¡ç®—å¤šæ ·æ€§ï¼Œç„¶åè½¬æ¢ä¸ºä¸“ä¸šåŒ–åˆ†æ•°
        total = target_counts.sum()
        probabilities = target_counts / total
        entropy = -sum(p * np.log2(p) for p in probabilities if p > 0)
        
        # æœ€å¤§ç†µï¼ˆå®Œå…¨å‡åŒ€åˆ†å¸ƒï¼‰
        max_entropy = np.log2(len(target_counts))
        
        # ä¸“ä¸šåŒ–åˆ†æ•° = 1 - æ ‡å‡†åŒ–ç†µ
        specialization = (1 - entropy / max_entropy) * 100 if max_entropy > 0 else 100
        
        return min(100.0, max(0.0, specialization))
    
    def _analyze_user_complexity_preference(self, user_data: pd.DataFrame) -> str:
        """åˆ†æç”¨æˆ·å¤æ‚åº¦åå¥½"""
        type_complexity = {
            'cuboid': 1,
            'polygon': 3,
            'polyline': 2,
            'issinstance': 4,
            'keypoint': 1
        }
        
        total_complexity = sum(
            len(user_data[user_data['normalized_instance_type'] == inst_type]) * type_complexity.get(str(inst_type), 2)
            for inst_type in user_data['normalized_instance_type'].unique()
        )
        
        avg_complexity = total_complexity / len(user_data) if len(user_data) > 0 else 0
        
        if avg_complexity <= 1.5:
            return "simple_preference"
        elif avg_complexity <= 2.5:
            return "moderate_preference"
        else:
            return "complex_preference"
    
    def _compare_user_targets(self, individual_targets: Dict) -> Dict[str, Any]:
        """æ¯”è¾ƒç”¨æˆ·ç›®æ ‡åå¥½"""
        if not individual_targets:
            return {}
        
        # æ‰¾å‡ºæœ€å¤šæ ·åŒ–çš„ç”¨æˆ·
        most_diverse_user = max(individual_targets.items(), key=lambda x: x[1]['target_diversity'])
        
        # æ‰¾å‡ºæœ€ä¸“ä¸šåŒ–çš„ç”¨æˆ·
        most_specialized_user = max(individual_targets.items(), key=lambda x: x[1]['specialization_score'])
        
        # æœ€é«˜äº§çš„ç”¨æˆ·
        most_productive_user = max(individual_targets.items(), key=lambda x: x[1]['total_annotations'])
        
        return {
            "most_diverse_user": {
                "user": most_diverse_user[0],
                "diversity_score": most_diverse_user[1]['target_diversity']
            },
            "most_specialized_user": {
                "user": most_specialized_user[0],
                "specialization_score": most_specialized_user[1]['specialization_score']
            },
            "most_productive_user": {
                "user": most_productive_user[0],
                "total_annotations": most_productive_user[1]['total_annotations']
            }
        }
    
    def _analyze_user_speed_trend(self, user_data: pd.DataFrame) -> str:
        """åˆ†æç”¨æˆ·é€Ÿåº¦è¶‹åŠ¿"""
        if len(user_data) < 5:
            return "insufficient_data"
        
        # å°†æ•°æ®åˆ†ä¸ºå‰åä¸¤åŠï¼Œæ¯”è¾ƒæ ‡æ³¨é—´éš”
        mid_point = len(user_data) // 2
        first_half = user_data.iloc[:mid_point]
        second_half = user_data.iloc[mid_point:]
        
        if len(first_half) < 2 or len(second_half) < 2:
            return "insufficient_data"
        
        first_half_interval = (first_half['time'].max() - first_half['time'].min()).total_seconds() / len(first_half)
        second_half_interval = (second_half['time'].max() - second_half['time'].min()).total_seconds() / len(second_half)
        
        if first_half_interval > 0:
            speed_change = (first_half_interval - second_half_interval) / first_half_interval
            
            if speed_change > 0.2:
                return "accelerating"
            elif speed_change < -0.2:
                return "decelerating"
            else:
                return "stable"
        
        return "stable"
    
    def _calculate_efficiency_level(self, annotations_per_hour: float) -> str:
        """è®¡ç®—æ•ˆç‡ç­‰çº§"""
        if annotations_per_hour >= 20:
            return "very_high"
        elif annotations_per_hour >= 10:
            return "high"
        elif annotations_per_hour >= 5:
            return "medium"
        elif annotations_per_hour >= 2:
            return "low"
        else:
            return "very_low"
    
    def _compare_user_speeds(self, individual_speeds: Dict) -> Dict[str, Any]:
        """æ¯”è¾ƒç”¨æˆ·é€Ÿåº¦"""
        if not individual_speeds:
            return {}
        
        # æå–é€Ÿåº¦æ•°æ®
        speed_data = {
            user: data['speed_metrics']['annotations_per_hour']
            for user, data in individual_speeds.items()
        }
        
        if not speed_data:
            return {}
        
        fastest_user = max(speed_data.items(), key=lambda x: x[1])
        slowest_user = min(speed_data.items(), key=lambda x: x[1])
        average_speed = sum(speed_data.values()) / len(speed_data)
        
        # é€Ÿåº¦ç­‰çº§åˆ†å¸ƒ
        level_distribution = {}
        for user, data in individual_speeds.items():
            level = data['efficiency_level']
            level_distribution[level] = level_distribution.get(level, 0) + 1
        
        return {
            "fastest_user": {
                "user": fastest_user[0],
                "speed": fastest_user[1]
            },
            "slowest_user": {
                "user": slowest_user[0],
                "speed": slowest_user[1]
            },
            "average_speed": average_speed,
            "speed_range": fastest_user[1] - slowest_user[1],
            "efficiency_level_distribution": level_distribution
        }
    
    def generate_enhanced_report(self, analysis: Dict[str, Any], hours: int = 1) -> str:
        """ç”Ÿæˆå¢å¼ºç‰ˆåˆ†ææŠ¥å‘Š"""
        report = f"""
{'='*100}
ğŸ¯ å¢å¼ºç‰ˆ 2D Instance æ•ˆç‡ç›‘æ§åˆ†ææŠ¥å‘Š
ğŸ“… æ—¶é—´èŒƒå›´: æœ€è¿‘ {hours} å°æ—¶
ğŸ• ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
{'='*100}

ğŸ“Š 1. æ€»ä½“æ ‡æ³¨ç›®æ ‡åˆ†æ
{'â”€'*70}"""
        
        targets_overall = analysis.get('annotation_targets_overall', {})
        if 'total_annotations' in targets_overall:
            report += f"\næ€»æ ‡æ³¨æ•°é‡: {targets_overall['total_annotations']}"
            report += f"\nç›®æ ‡ç±»å‹å¤šæ ·æ€§: {targets_overall['target_diversity']} ç§"
            report += f"\næœ€å¸¸è§ç›®æ ‡: {targets_overall['most_common_target']}\n"
            
            report += "\nğŸ¯ ç›®æ ‡ç±»å‹åˆ†å¸ƒ:"
            for target_type, count in targets_overall['target_type_distribution'].items():
                percentage = targets_overall['target_type_percentages'].get(target_type, 0)
                report += f"\n  {target_type}: {count} ä¸ª ({percentage:.1f}%)"
            
            complexity = targets_overall.get('target_complexity', {})
            if complexity:
                report += f"\n\nğŸ”§ ç›®æ ‡å¤æ‚åº¦åˆ†æ:"
                report += f"\n  ç®€å•å½¢çŠ¶: {complexity.get('simple_shapes', 0)} ä¸ª"
                report += f"\n  å¤æ‚å½¢çŠ¶: {complexity.get('complex_shapes', 0)} ä¸ª"
                report += f"\n  å¹³å‡å¤æ‚åº¦: {complexity.get('average_complexity', 0):.1f}/4"
        
        report += f"""

ğŸš€ 2. æ€»ä½“æ ‡æ³¨é€Ÿåº¦åˆ†æ
{'â”€'*70}"""
        
        speed_overall = analysis.get('annotation_speed_overall', {})
        if 'overall_speed' in speed_overall:
            overall = speed_overall['overall_speed']
            time_info = speed_overall.get('time_range', {})
            
            report += f"\nâ° æ—¶é—´ä¿¡æ¯:"
            report += f"\n  å¼€å§‹æ—¶é—´: {time_info.get('start', 'N/A')}"
            report += f"\n  ç»“æŸæ—¶é—´: {time_info.get('end', 'N/A')}"
            report += f"\n  æŒç»­æ—¶é•¿: {time_info.get('duration_hours', 0):.1f} å°æ—¶"
            
            report += f"\n\nğŸ“ˆ æ•´ä½“é€Ÿåº¦æŒ‡æ ‡:"
            report += f"\n  æ¯å°æ—¶æ ‡æ³¨æ•°: {overall['annotations_per_hour']:.1f} ä¸ª/å°æ—¶"
            report += f"\n  æ¯åˆ†é’Ÿæ ‡æ³¨æ•°: {overall['annotations_per_minute']:.2f} ä¸ª/åˆ†é’Ÿ"
            report += f"\n  å¹³å‡æ ‡æ³¨é—´éš”: {overall['average_time_between_annotations']:.0f} ç§’"
            
            speed_by_type = speed_overall.get('speed_by_type', {})
            if speed_by_type:
                report += f"\n\nğŸ¯ å„ç±»å‹æ ‡æ³¨é€Ÿåº¦:"
                for target_type, speed_data in speed_by_type.items():
                    report += f"\n  {target_type}: {speed_data['annotations_per_hour']:.1f} ä¸ª/å°æ—¶ ({speed_data['percentage_of_total']:.1f}%)"
            
            # æ·»åŠ æŒ‰ç±»å‹çš„å¹³å‡å®Œæˆæ—¶é—´åˆ†æ
            completion_time = speed_overall.get('completion_time_by_type', {})
            if completion_time and 'error' not in completion_time:
                report += f"\n\nâ±ï¸ å¹³å‡å®Œæˆæ—¶é—´åˆ†æ (æŒ‰ç±»å‹):"
                
                # æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡
                overall_time = completion_time.get('overall', {})
                if overall_time:
                    report += f"\n  æ€»ä½“å¹³å‡: {overall_time.get('average_completion_time', 0):.1f} {overall_time.get('unit', 'ç§’')}"
                    report += f" (ä¸­ä½æ•°: {overall_time.get('median_completion_time', 0):.1f}{overall_time.get('unit', 'ç§’')})"
                
                # æŒ‰ç±»å‹æ˜¾ç¤º
                for target_type, time_data in completion_time.items():
                    if target_type != 'overall' and isinstance(time_data, dict) and 'average_completion_time' in time_data:
                        avg_time = time_data['average_completion_time']
                        min_time = time_data['min_completion_time']
                        max_time = time_data['max_completion_time']
                        unit = time_data.get('unit', 'ç§’')
                        
                        report += f"\n  {target_type}: å¹³å‡ {avg_time:.1f}{unit}"
                        report += f" (èŒƒå›´: {min_time:.1f}-{max_time:.1f}{unit})"
                        
                        # æ˜¾ç¤ºåˆ†ä½æ•°ä¿¡æ¯
                        percentiles = time_data.get('percentiles', {})
                        if percentiles:
                            report += f" [25%-75%: {percentiles.get('25th', 0):.1f}-{percentiles.get('75th', 0):.1f}{unit}]"
            elif completion_time and 'error' in completion_time:
                report += f"\n\nâ±ï¸ å®Œæˆæ—¶é—´åˆ†æ: {completion_time['error']}"
            
            hourly = speed_overall.get('hourly_patterns', {})
            if hourly:
                report += f"\n\nâ° æ—¶é—´æ¨¡å¼åˆ†æ:"
                report += f"\n  æœ€é«˜äº§æ—¶æ®µ: {hourly.get('peak_hour', 'N/A')}:00 ({hourly.get('peak_hour_count', 0)} ä¸ª)"
                productive_hours = hourly.get('most_productive_hours', {})
                report += f"\n  æœ€é«˜äº§æ—¶é—´æ®µ: {', '.join(f'{h}:00({c}ä¸ª)' for h, c in list(productive_hours.items())[:3])}"
        
        report += f"""

ğŸ‘¤ 3. ä¸ªäººæ ‡æ³¨ç›®æ ‡åˆ†æ
{'â”€'*70}"""
        
        targets_individual = analysis.get('annotation_targets_individual', {})
        individual_data = targets_individual.get('individual_analysis', {})
        
        if individual_data:
            report += f"\nğŸ“Š ç”¨æˆ·ç›®æ ‡åå¥½:"
            for user, data in individual_data.items():
                report += f"\n\nç”¨æˆ· {user}:"
                report += f"\n  æ€»æ ‡æ³¨æ•°: {data['total_annotations']}"
                report += f"\n  ç›®æ ‡å¤šæ ·æ€§: {data['target_diversity']} ç§"
                report += f"\n  ä¸“ä¸šåŒ–åˆ†æ•°: {data['specialization_score']:.1f}/100"
                report += f"\n  å¤æ‚åº¦åå¥½: {data['complexity_preference']}"
                report += f"\n  æœ€å¸¸æ ‡æ³¨: {data['most_common_target']}"
                
                target_dist = data.get('target_distribution', {})
                if target_dist:
                    report += f"\n  ç±»å‹åˆ†å¸ƒ: {', '.join(f'{t}({c}ä¸ª)' for t, c in target_dist.items())}"
            
            comparison = targets_individual.get('comparison_analysis', {})
            if comparison:
                report += f"\n\nğŸ† ç”¨æˆ·å¯¹æ¯”:"
                if 'most_diverse_user' in comparison:
                    diverse = comparison['most_diverse_user']
                    report += f"\n  æœ€å¤šæ ·åŒ–: {diverse['user']} ({diverse['diversity_score']} ç§ç±»å‹)"
                if 'most_specialized_user' in comparison:
                    specialized = comparison['most_specialized_user']
                    report += f"\n  æœ€ä¸“ä¸šåŒ–: {specialized['user']} (ä¸“ä¸šåŒ–åˆ†æ•°: {specialized['specialization_score']:.1f})"
                if 'most_productive_user' in comparison:
                    productive = comparison['most_productive_user']
                    report += f"\n  æœ€é«˜äº§: {productive['user']} ({productive['total_annotations']} ä¸ªæ ‡æ³¨)"
        
        report += f"""

âš¡ 4. ä¸ªäººæ ‡æ³¨é€Ÿåº¦åˆ†æ
{'â”€'*70}"""
        
        speed_individual = analysis.get('annotation_speed_individual', {})
        individual_speed_data = speed_individual.get('individual_analysis', {})
        
        if individual_speed_data:
            report += f"\nğŸš€ ç”¨æˆ·é€Ÿåº¦è¡¨ç°:"
            for user, data in individual_speed_data.items():
                session = data.get('session_info', {})
                metrics = data.get('speed_metrics', {})
                
                report += f"\n\nç”¨æˆ· {user}:"
                report += f"\n  ä¼šè¯æ—¶é•¿: {session.get('duration_hours', 0):.1f} å°æ—¶"
                report += f"\n  æ€»æ ‡æ³¨æ•°: {session.get('total_annotations', 0)}"
                report += f"\n  æ ‡æ³¨é€Ÿåº¦: {metrics.get('annotations_per_hour', 0):.1f} ä¸ª/å°æ—¶"
                report += f"\n  æ•ˆç‡ç­‰çº§: {data.get('efficiency_level', 'unknown')}"
                report += f"\n  é€Ÿåº¦è¶‹åŠ¿: {data.get('speed_trend', 'unknown')}"
                
                speed_by_type = data.get('speed_by_type', {})
                if speed_by_type:
                    report += f"\n  åˆ†ç±»é€Ÿåº¦: {', '.join(f'{t}({s:.1f}/å°æ—¶)' for t, s in {k: v['annotations_per_hour'] for k, v in speed_by_type.items()}.items())}"
                
                # ç”¨æˆ·çš„å®Œæˆæ—¶é—´åˆ†æ
                user_completion_time = data.get('completion_time_by_type', {})
                if user_completion_time and 'error' not in user_completion_time:
                    report += f"\n  å®Œæˆæ—¶é—´:"
                    
                    # æ˜¾ç¤ºç”¨æˆ·æ€»ä½“å®Œæˆæ—¶é—´
                    overall_time = user_completion_time.get('overall', {})
                    if overall_time:
                        avg_time = overall_time.get('average_completion_time', 0)
                        unit = overall_time.get('unit', 'ç§’')
                        report += f" å¹³å‡{avg_time:.1f}{unit}"
                    
                    # æ˜¾ç¤ºå„ç±»å‹å®Œæˆæ—¶é—´
                    type_times = []
                    for target_type, time_data in user_completion_time.items():
                        if target_type != 'overall' and isinstance(time_data, dict) and 'average_completion_time' in time_data:
                            avg_time = time_data['average_completion_time']
                            unit = time_data.get('unit', 'ç§’')
                            type_times.append(f"{target_type}({avg_time:.1f}{unit})")
                    
                    if type_times:
                        report += f", åˆ†ç±»: {', '.join(type_times)}"
            
            speed_comparison = speed_individual.get('speed_comparison', {})
            if speed_comparison:
                report += f"\n\nğŸ é€Ÿåº¦å¯¹æ¯”:"
                if 'fastest_user' in speed_comparison:
                    fastest = speed_comparison['fastest_user']
                    report += f"\n  æœ€å¿«ç”¨æˆ·: {fastest['user']} ({fastest['speed']:.1f} ä¸ª/å°æ—¶)"
                if 'slowest_user' in speed_comparison:
                    slowest = speed_comparison['slowest_user']
                    report += f"\n  æœ€æ…¢ç”¨æˆ·: {slowest['user']} ({slowest['speed']:.1f} ä¸ª/å°æ—¶)"
                if 'average_speed' in speed_comparison:
                    report += f"\n  å¹³å‡é€Ÿåº¦: {speed_comparison['average_speed']:.1f} ä¸ª/å°æ—¶"
                
                level_dist = speed_comparison.get('efficiency_level_distribution', {})
                if level_dist:
                    report += f"\n  æ•ˆç‡åˆ†å¸ƒ: {', '.join(f'{level}({count}äºº)' for level, count in level_dist.items())}"
        
        report += f"\n\n{'='*100}\nğŸ“‹ å¢å¼ºç‰ˆåˆ†ææŠ¥å‘Šç»“æŸ\n{'='*100}"
        
        return report
    
    def run_enhanced_analysis(self, hours: int = 1) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„å¢å¼ºç‰ˆåˆ†æ"""
        # æŸ¥è¯¢æ•°æ®
        records = self.query_2d_instance_data(hours)
        
        if not records:
            return {"error": "æ— æ³•è·å–æ•°æ®"}
        
        if len(records) == 0:
            return {"error": f"æœ€è¿‘ {hours} å°æ—¶å†…æ²¡æœ‰2D Instanceæ•°æ®"}
        
        # è½¬æ¢ä¸ºDataFrame
        df = pd.DataFrame(records)
        
        print("ğŸ” æ­£åœ¨è¿›è¡Œå¢å¼ºç‰ˆ2D Instanceåˆ†æ...")
        
        # æ‰§è¡Œåˆ†æ
        analysis = {
            "annotation_targets_overall": self.analyze_annotation_targets_overall(df),
            "annotation_speed_overall": self.analyze_annotation_speed_overall(df),
            "annotation_targets_individual": self.analyze_annotation_targets_individual(df),
            "annotation_speed_individual": self.analyze_annotation_speed_individual(df),
            "data_overview": {
                "total_records": len(records),
                "time_range": {
                    "start": df['time'].min() if 'time' in df.columns else None,
                    "end": df['time'].max() if 'time' in df.columns else None
                },
                "available_fields": list(df.columns)
            }
        }
        
        return analysis
    
    def close(self):
        """å…³é—­è¿æ¥"""
        if self.client:
            self.client.close()

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='å¢å¼ºç‰ˆ2D Instanceæ•ˆç‡ç›‘æ§åˆ†æå·¥å…·')
    parser.add_argument('--hours', type=int, default=1, help='åˆ†ææœ€è¿‘å¤šå°‘å°æ—¶çš„æ•°æ® (é»˜è®¤: 1)')
    parser.add_argument('--output', type=str, help='è¾“å‡ºæŠ¥å‘Šåˆ°æ–‡ä»¶')
    parser.add_argument('--json', action='store_true', help='è¾“å‡º JSON æ ¼å¼çš„åˆ†æç»“æœ')
    
    args = parser.parse_args()
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = Enhanced2DAnalyzer()
    
    try:
        # è¿æ¥æ•°æ®åº“
        if not analyzer.connect():
            sys.exit(1)
        
        # è¿è¡Œåˆ†æ
        analysis = analyzer.run_enhanced_analysis(args.hours)
        
        if "error" in analysis:
            print(f"âŒ åˆ†æå¤±è´¥: {analysis['error']}")
            sys.exit(1)
        
        if args.json:
            # è¾“å‡º JSON æ ¼å¼
            result = json.dumps(analysis, indent=2, default=str, ensure_ascii=False)
        else:
            # ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š
            result = analyzer.generate_enhanced_report(analysis, args.hours)
        
        # è¾“å‡ºç»“æœ
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                f.write(result)
            print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.output}")
        else:
            print(result)
            
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)
    finally:
        analyzer.close()

if __name__ == "__main__":
    main() 